{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ramdom Forest with Resampled\n",
    "\n",
    "#### Created on Sat Dec  9 18:50:03 2017\n",
    "\n",
    "#### Author: tpin3694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import scikitplot as skplt\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data reader function, to return the orederd_product_key and campaign_key columns from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_reader(file):\n",
    "    data_read = pd.read_csv(file)\n",
    "    data = data_read.drop([\"Ordered_Product_Key\", \"Campaign_Key\"], 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks for NaNs and if any fraud actually exists in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_checker(dataframe):\n",
    "    num_nan = np.sum(dataframe.isnull().sum())\n",
    "    num_fraud = dataframe['fraud_status'].sum()\n",
    "    return num_nan, num_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses SMOTE and Tomek Links to under and over sample to combat the class imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_smote(feature, label):\n",
    "    print(\"Raw Data: \" + str(sorted(Counter(label).items())))\n",
    "    smt = SMOTETomek(random_state=42)\n",
    "    feature_resampled, label_resampled = smt.fit_sample(feature, label)\n",
    "    print(\"Resampled: \" + str(sorted(Counter(label_resampled).items())))\n",
    "    return feature_resampled, label_resampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot socres for different trees and save the plot in the local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotter(scores, array1, array2, tree_list, directory, file_write):\n",
    "    plt.plot(tree_list, scores)\n",
    "    plt.plot(tree_list, array1 + array2, 'b--')\n",
    "    plt.plot(tree_list, array1 - array2, 'b--')\n",
    "    plt.ylabel('CV score')\n",
    "    plt.xlabel('# of trees')\n",
    "    plt.savefig(directory + 'accuracy_plots/dataset' + str(file_write).strip(file_dir) + \".png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the model recall, precision, f1 and auc value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_scorer(model, features, labels, folds):\n",
    "    recall = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"recall\", n_jobs = -1))\n",
    "    precision = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"precision\", n_jobs = -1))\n",
    "    accuracy = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"accuracy\", n_jobs = -1))\n",
    "    f1 = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"f1\", n_jobs = -1))\n",
    "    auc = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"roc_auc\", n_jobs = -1))\n",
    "    return accuracy, recall, precision, f1, auc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test model with features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(no_trees, features, labels):\n",
    "    random_forest = RandomForestClassifier(no_trees)\n",
    "    model_metric = cross_val_score(random_forest, features, labels)\n",
    "    return model_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup File Structure and create a data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = \"/Users/sunmengnan/Documents/Github2/thgfd/data/stratified/\"\n",
    "files = glob.glob(file_dir + \"dataset*.csv\")\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each file in the file list, the main process is: read in data, then check for any fraud, for each site, split out into test and train data set, and seperate labels and features, train classifier, define variable importances, remove the umimportant variables, retrain model, check there are enough minority cases to run 10 fold cross-validation and return matrix, finally calculate prediction probabilitiesÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_119.csv\n",
      "Raw Data: [(0, 142571), (1, 415)]\n",
      "Resampled: [(0, 142443), (1, 142443)]\n",
      "_121.csv\n",
      "Raw Data: [(0, 142571), (1, 415)]\n",
      "Resampled: [(0, 142443), (1, 142443)]\n",
      "_120.csv\n",
      "Raw Data: [(0, 142571), (1, 415)]\n",
      "Resampled: [(0, 142443), (1, 142443)]\n",
      "_153.csv\n",
      "Raw Data: [(0, 142571), (1, 415)]\n",
      "Resampled: [(0, 142443), (1, 142443)]\n",
      "_11.csv\n",
      "Raw Data: [(0, 142571), (1, 415)]\n",
      "Resampled: [(0, 142443), (1, 142443)]\n",
      "_15.csv\n",
      "Raw Data: [(0, 142571), (1, 415)]\n",
      "Resampled: [(0, 142443), (1, 142443)]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for file in files:\n",
    "    filename = file.strip(file_dir)\n",
    "#     site = data_reader(file)\n",
    "#     file_checks = file_checker(site)\n",
    "#     if file_checks[1] > 0:\n",
    "    print(str(filename))\n",
    "    train, test = train_test_split(site, test_size = 0.5, random_state = 42)\n",
    "    train_x = train.loc[:, train.columns != \"fraud_status\"]\n",
    "    train_y = train['fraud_status']\n",
    "    test_x = test.loc[:, test.columns != \"fraud_status\"]\n",
    "    test_y = test['fraud_status']   \n",
    "    train_x, train_y = get_smote(train_x, train_y)\n",
    "#         classifier = RandomForestClassifier(80)\n",
    "#         classifier.fit(train_x, train_y)\n",
    "#         importances = pd.Series(classifier.feature_importances_, name = \"Importances\")\n",
    "#         var_importance = pd.concat([pd.Series(test_x.columns, name = \"Names\"), importances], 1)\n",
    "#         var_importance = var_importance.sort_values(by = \"Importances\", ascending = False).reset_index()\n",
    "#         var_importance = var_importance.drop(\"index\", 1)\n",
    "#         sns.set_style('ticks')\n",
    "#         fig, ax = plt.subplots()\n",
    "#         fig.set_size_inches(w = 20, h = 20)\n",
    "#         sns.barplot(y = \"Names\", x = \"Importances\", data = var_importance, ax = ax)\n",
    "#         sns.despine()\n",
    "#         unimportant = var_importance.drop(var_importance[var_importance.Importances < 0.0001].index)\n",
    "#         unimportant = unimportant[\"Names\"]\n",
    "#         train_x = pd.DataFrame(train_x)\n",
    "#         train_x.columns = train.loc[:, train.columns != \"fraud_status\"].columns\n",
    "#         train_x = train_x[unimportant]\n",
    "#         train_x = train_x.as_matrix()\n",
    "#         test_x = test[unimportant].values\n",
    "#         test_y = test['fraud_status'].values\n",
    "#         clf = RandomForestClassifier(80, n_jobs = -1, random_state=42)\n",
    "#         clf.fit(train_x, train_y)\n",
    "#         clf.predict(test_x)\n",
    "#         if sum(test_y) < 10:\n",
    "#             cv = sum(test_y)\n",
    "#         else:\n",
    "#             cv = 10\n",
    "#         accuracy, recall, precision, f_score, auc = data_scorer(clf, test_x, test_y, cv)\n",
    "#         results = [filename, accuracy, recall, precision, f_score, auc]\n",
    "#         y_prob = clf.predict_proba(test_x)\n",
    "#         y_pred = clf.predict(test_x)\n",
    "        \n",
    "#         data_list.append(results)\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "# results_df = pd.DataFrame(data_list, columns = [\"File\",\"Accuracy\", \" recall\", \"precision\", \"f_score\", \"auc\"])\n",
    "# results_df.to_csv(\"/Users/sunmengnan/Desktop/FD/result1/smote_random_forest_results.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output our result as a csv file into the local fileÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data_list, columns = [\"File\",\"Accuracy\", \" recall\", \"precision\", \"f_score\", \"auc\"])\n",
    "results_df.to_csv(\"/home/tpin3694/Documents/university/MSc/fundamental/fraud/data/smote_random_forest_results.csv\",index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
