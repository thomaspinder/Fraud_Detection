{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import scikitplot as skplt\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.combine import SMOTETomek \n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Reader function\n",
    "This function drops the ordered_product_key and the campaign_key columns from a given file as whilst needed when creating the dataset for joins.etc, they serve no use when trying to model fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_reader(file):\n",
    "    data_read = pd.read_csv(file)\n",
    "    data = data_read.drop([\"Ordered_Product_Key\", \"Campaign_Key\"], 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NaN function\n",
    "Naturally. it is impossibly to model fraud if no fraud actually exists in a specific site. For a given dataframe, this function returns the number of NaN values within a dataset as well as the number of total number of fraudulent observations, if any at all. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_checker(dataframe):\n",
    "    num_nan = np.sum(dataframe.isnull().sum())\n",
    "    num_fraud = dataframe['fraud_status'].sum()\n",
    "    return num_nan, num_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SMOTE function ???\n",
    "This function applies Tomek line and SMOTE to the dataset, allowing for fraud to be better modelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_smote(feature, label):\n",
    "    print(\"Raw Data: \" + str(sorted(Counter(label).items())))\n",
    "    smt = SMOTETomek(random_state=42)\n",
    "    feature_resampled, label_resampled = smt.fit_sample(feature, label)\n",
    "    print(\"Resampled: \" + str(sorted(Counter(label_resampled).items())))\n",
    "    return feature_resampled, label_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cross-validation scores\n",
    "For each of the 6 sites, this function plots the cross-validation scores vs. the number of trees. Additionally, this saves each graph as a .png file within a local directory. This function was used when determining the number of trees needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotter(scores, array1, array2, tree_list, directory, file_write):\n",
    "    plt.plot(tree_list, scores)\n",
    "    plt.plot(tree_list, array1 + array2, 'b--')\n",
    "    plt.plot(tree_list, array1 - array2, 'b--')\n",
    "    plt.ylabel('CV score')\n",
    "    plt.xlabel('# of trees')\n",
    "    plt.savefig(directory + 'accuracy_plots/dataset' + str(file_write).strip(file_dir) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Metric function\n",
    "This function calculates and returns the recall, precision, accuracy, F-score, and AUC of a particular model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_scorer(model, features, labels, folds):\n",
    "    recall = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"recall\", n_jobs = -1))\n",
    "    precision = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"precision\", n_jobs = -1))\n",
    "    accuracy = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"accuracy\", n_jobs = -1))\n",
    "    f1 = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"f1\", n_jobs = -1))\n",
    "    auc = np.mean(cross_val_score(model, X = features, y = labels, cv = folds, scoring = \"roc_auc\", n_jobs = -1))\n",
    "    return accuracy, recall, precision, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = \"/Users/Nick/Desktop/datafundamentals/thgfd/data/stratified \"\n",
    "files = glob.glob(file_dir + \"dataset*.csv\")\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Processing and Modelling the data\n",
    "This is where the modelling happens, via a for loop. This whole process is automated by looping through a directory containing each of the datasets, producing a model, storing the model's metrics, writing to a .csv file and then moving onto the next file.\n",
    "\n",
    "#### Data read and validate\n",
    "The data is first read in, a variable of the file's name is created and then the data is checked for the presence of fraud. If this presence is confirmed, then the data is split into a testing and training set, with labels split out too. \n",
    "\n",
    "#### Modelling\n",
    "The training data is then passed through a random forest, using 80 trees. Once the model has been trained, variable importances are extracted and unimportant variables are then removed from the training and testing set. The model is then fitted again, using only the important variables.\n",
    "\n",
    "#### Testing\n",
    "The testing data is then passed through the model and, using cross validation, accuracy, precision, recall, f-score and auc are extracted. A confusion matrix and ROC plot are also created and saved to a .png file. The final model metrics and then written to csv and the loop proceeds to the next file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for file in files:\n",
    "    filename = file.strip(file_dir)\n",
    "    site = data_reader(file)\n",
    "    file_checks = file_checker(site)\n",
    "    if file_checks[1] > 0:\n",
    "        train, test = train_test_split(site, test_size = 0.5, random_state = 42)\n",
    "        train_x = train.loc[:, train.columns != \"fraud_status\"]\n",
    "        train_y = train['fraud_status']\n",
    "        test_x = test.loc[:, test.columns != \"fraud_status\"]\n",
    "        test_y = test['fraud_status']\n",
    "        classifier = RandomForestClassifier(80)\n",
    "        classifier.fit(train_x, train_y)\n",
    "        importances = pd.Series(classifier.feature_importances_, name = \"Importances\")\n",
    "        var_importance = pd.concat([pd.Series(test_x.columns, name = \"Names\"), importances], 1)\n",
    "        var_importance = var_importance.sort_values(by = \"Importances\", ascending = False).reset_index()\n",
    "        var_importance = var_importance.drop(\"index\", 1)\n",
    "        sns.set_style('ticks')\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(w = 20, h = 20)\n",
    "        sns.barplot(y = \"Names\", x = \"Importances\", data = var_importance, ax = ax)\n",
    "        sns.despine()\n",
    "        fig.savefig(\"/Users/sunmengnan/Desktop/FD/plot/\" +\n",
    "                    filename+ \"variable_importance_no_smote.png\")\n",
    "        \n",
    "        unimportant = var_importance.drop(var_importance[var_importance.Importances < 0.0001].index)\n",
    "        unimportant = unimportant[\"Names\"]\n",
    "        unimportant.to_csv(\"/Users/sunmengnan/Desktop/FD/result/\"+\n",
    "                           filename + \"important_variables.csv\",index = True)\n",
    "        \n",
    "        train_x = pd.DataFrame(train_x)\n",
    "        train_x.columns = train.loc[:, train.columns != \"fraud_status\"].columns\n",
    "        train_x = train_x[unimportant]\n",
    "        train_x = train_x.as_matrix()\n",
    "        test_x = test[unimportant].values\n",
    "        test_y = test['fraud_status'].values\n",
    "        \n",
    "        clf = RandomForestClassifier(80, n_jobs = -1, random_state=42)\n",
    "        clf.fit(train_x, train_y)\n",
    "        clf.predict(test_x)\n",
    "\n",
    "        if sum(test_y) < 10:\n",
    "            cv = sum(test_y)\n",
    "        else:\n",
    "            cv = 10\n",
    "        \n",
    "        accuracy, recall, precision, f_score, auc = data_scorer(clf, test_x, test_y, cv)\n",
    "        results = [filename, accuracy, recall, precision, f_score, auc]\n",
    "          \n",
    "        y_prob = clf.predict_proba(test_x)\n",
    "        y_pred = clf.predict(test_x)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(w = 20, h = 20)\n",
    "        skplt.metrics.plot_roc_curve(test_y, y_prob, title = \"Random Forest ROC Site \" + filename ,\n",
    "                                     ax = ax, title_fontsize=46, text_fontsize = 30)\n",
    "        fig.savefig(\"/Users/sunmengnan/Desktop/FD/plot/\" + filename + \"rf_roc_no_smote.png\")\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(w = 20, h = 20)\n",
    "        skplt.metrics.plot_confusion_matrix(test_y, y_pred, normalize = True, ax = ax,\n",
    "                                            text_fontsize=30, title_fontsize=46, \n",
    "                                            title=\"Normalised Confusion Matrix\")\n",
    "        \n",
    "        fig.savefig(\"/Users/sunmengnan/Desktop/FD/plot/\"+ filename + \"rf_confusion_no_smote.png\")\n",
    "        data_list.append(results)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sunmengnan/Desktop/FD/plot/_11.csvrf_confusion_no_smote.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ca230edb2ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/sunmengnan/Desktop/FD/plot/_11.csvrf_confusion_no_smote.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sunmengnan/Desktop/FD/plot/_11.csvrf_confusion_no_smote.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"/Users/sunmengnan/Desktop/FD/plot/_11.csvrf_confusion_no_smote.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename=\"/Users/sunmengnan/Desktop/FD/plot/_11.csvrf_roc_no_smote.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename=\"/Users/sunmengnan/Desktop/FD/plot/_11.csvvariable_importance_no_smote.png\",width=1200,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data_list, columns = [\"File\",\"Accuracy\", \" recall\", \"precision\", \"f_score\", \"auc\"])\n",
    "results_df.to_csv(\"/Users/sunmengnan/Desktop/FD/result/random_forest_results.csv\",\n",
    "                  index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
